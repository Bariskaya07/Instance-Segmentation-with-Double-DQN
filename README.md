
## Double DQN ve Reinforcement Learning YaklaÅŸÄ±mÄ±yla Instance Segmentation

Bu proje, standart **Mask R-CNN** mimarisine entegre edilen **Double Deep Q-Network (Double DQN)** yapÄ±sÄ±yla gÃ¼Ã§lendirilmiÅŸ bir instance segmentation (nesne bazlÄ± bÃ¶lÃ¼tleme) sistemi sunar. AmaÃ§, piksel dÃ¼zeyindeki segmentasyon kalitesini artÄ±rmak ve maske iyileÅŸtirme sÃ¼recini **IoU (Intersection over Union)** deÄŸerlerine dayalÄ± **Ã¶dÃ¼l sinyalleri** ile yÃ¶nlendirilen ardÄ±ÅŸÄ±l bir karar verme problemine dÃ¶nÃ¼ÅŸtÃ¼rerek Ã¶ÄŸrenmeyi daha akÄ±llÄ± hale getirmektir.


## Reinforcement Learning Approach to Instance Segmentation Using Double DQN

This project presents a reinforcement learning-enhanced instance segmentation pipeline that integrates a **Double Deep Q-Network (Double DQN)** into a standard **Mask R-CNN** framework. The goal is to improve the pixel-level segmentation quality by treating mask refinement as a sequential decision-making problem, guided by **reward signals** based on **IoU (Intersection over Union)** improvements.
---
## ğŸ§  Motivation

Instance segmentation requires high-quality, fine-grained object masks â€” especially in complex scenes with occlusions and clutter. While **Mask R-CNN** is powerful, it relies heavily on supervised learning and large annotated datasets. This project introduces **reinforcement learning (RL)** to enhance mask quality with a **Double DQN** module that learns to refine predictions based on experience and feedback.

---

## ğŸ§° Key Contributions

1. **RL-enhanced Mask R-CNN**: Adds a Double DQN-based mask refinement policy to a pretrained Mask R-CNN.
2. **Reward-driven Optimization**: Rewards are based on IoU improvement, guiding the agent toward better mask alignment.
3. **No Additional Epochs Needed**: Significant performance boost is achieved without extending total training time.
4. **+57% AP boost**: Compared to a supervised-only Mask R-CNN baseline.
````markdown
## ğŸ“¦ Project Structure

```bash
instance-segmentation-rl/
â”œâ”€â”€ segmentation/               # Reinforcement-enhanced Mask R-CNN module
â”‚   â”œâ”€â”€ class_names.py
â”‚   â”œâ”€â”€ coco_eval.py
â”‚   â”œâ”€â”€ coco_utils.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â”œâ”€â”€ group_by_aspect_ratio.py
â”‚   â”œâ”€â”€ infer_utils.py
â”‚   â”œâ”€â”€ inference_image.py
â”‚   â”œâ”€â”€ inference_video.py
â”‚   â”œâ”€â”€ presets.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ transforms.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ results/                    # Result figures, metrics, and output videos
â”œâ”€â”€ configs/                    # YAML or JSON configs for training
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
````

---

## ğŸ§ª Methodology

### ğŸ§± Base Architecture: Mask R-CNN

* Backbone: ResNet-50 FPN
* Dataset: COCO 2017 Instance Segmentation

### ğŸ” RL Module: Double DQN

* State: Segmentation mask grid
* Action Space:

  * Dilation
  * Erosion
  * No-op
* Reward: IoU gain compared to previous mask
* Exploration: Epsilon-greedy strategy

### ğŸ§® Training Flow

* Epochs 1â€“3: Mask R-CNN trains with supervised loss
* Epochs 4â€“10: Double DQN takes over for iterative mask refinement
* Q-values updated with experience replay and target networks

---

## ğŸ“Š Results

| Metric                       | Baseline (Mask R-CNN) | RL-Enhanced (Ours) |
| ---------------------------- | --------------------- | ------------------ |
| AP@\[0.50:0.95]              | 0.171                 | **0.268** (+57%)   |
| AP\@0.50                     | 0.305                 | **0.444** (+46%)   |
| AP\@0.75                     | 0.169                 | **0.283** (+67%)   |
| AR@\[0.50:0.95] (maxDet=100) | 0.330                 | **0.338**          |

> ğŸ§  Our model achieved **faster convergence**, higher-quality masks, and better generalization without needing longer training schedules.

---

## ğŸ”§ How to Use

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Train Mask R-CNN + Double DQN

```bash
python segmentation/train.py --epochs 10 --rl_start_epoch 4
```

### Run Inference on Images

```bash
python segmentation/inference_image.py --input input.jpg --output result.png
```

### Run Inference on Videos

```bash
python segmentation/inference_video.py --input input.mp4 --output result.mp4
```


## ğŸ“ Citation (APA)

Kaya, B., DenkÄ±nalbant, A., Ahangari, M., Saidburkhan, A., & ArÄ±can, E. (2025). *Reinforcement Learning Approach to Instance Segmentation Using Double DQN*. BahÃ§eÅŸehir University.

---

## ğŸ“œ License

MIT License â€” see [`LICENSE`](./LICENSE) for full details.

---

## ğŸ™ Acknowledgements

This research was supported by BahÃ§eÅŸehir University. We also thank:

* **Dr. Erkut ArÄ±can** for mentoring and project supervision.
* Open-source contributors from **Detectron2**, **PyTorch**, and **COCO** dataset community.

---

```
```
